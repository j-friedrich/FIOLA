#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Mar 22 15:32:31 2021

@author: nel
"""

#%%
import tensorflow as tf
import numpy as np
import pylab as plt
import tensorflow.keras as keras
import tensorflow_addons as tfa
import timeit
#%%
class MotionCorrect(keras.layers.Layer):
    def __init__(self, template, ms_h=10, ms_w=10, switch=0, strides=[1,1,1,1], padding='VALID', epsilon=0.00000001, **kwargs):
        
        super().__init__(**kwargs)
        
        self.ms_h = ms_h
        self.ms_w = ms_w
        
        self.strides = strides
        self.padding = padding
        self.epsilon =  epsilon
        
        self.template = template
        self.template_zm, self.template_var = self.normalize_template(self.template, epsilon=self.epsilon)
        
        self.shp = self.template.shape
        self.shp_prod = tf.cast(tf.reduce_prod(self.shp), tf.float32)

        self.shp_m_x, self.shp_m_y = self.shp[0]//2, self.shp[1]//2
                
        self.target_freq = tf.signal.fft3d(tf.cast(self.template_zm[:,:,:,0], tf.complex128))
        self.switch = switch
            
       
    @tf.function
    def call(self, fr):
        # print(fr.shape)
        # fr = tf.cast(fr[None, :, :, None], tf.float32)
        fr =  fr[0][None,:]
        # print(fr_center.shape, fr_center.dtype)
        # print(self.shp)
        imgs_zm, imgs_var = self.normalize_image(fr, self.shp, strides=self.strides,
                                            padding=self.padding, epsilon=self.epsilon)
        denominator = tf.sqrt(self.template_var * imgs_var)

        fr_freq = tf.signal.fft3d(tf.cast(imgs_zm[0], tf.complex128))
        img_product = fr_freq *  tf.math.conj(self.target_freq)

        cross_correlation = tf.cast(tf.math.abs(tf.signal.ifft3d(img_product)), tf.float32)[None,:]
        # print(cross_correlation.shape, img_product.shape, self.shp_m_x)
        # print(self.shp_m_x, self.shp_m_y)
        rolled_cc =  tf.roll(cross_correlation,(self.shp_m_x,self.shp_m_y), axis=(1,2))
        # print(rolled_cc.shape)
        # ncc = rolled_cc[:,self.shp_m_x-self.ms_w:self.shp_m_x+self.ms_w+1, self.shp_m_y-self.ms_h:self.shp_m_y+self.ms_h+1]/denominator
        ncc = rolled_cc[:,self.shp_m_x-self.ms_w:self.shp_m_x+self.ms_w+1, self.shp_m_y-self.ms_h:self.shp_m_y+self.ms_h+1]/denominator
        ncc = tf.where(tf.math.is_nan(ncc), tf.zeros_like(ncc), ncc)
        # plt.imshow(tf.squeeze(ncc))
        # print(tf.math.reduce_sum(ncc))
        
        sh_x, sh_y = self.extract_fractional_peak(ncc, self.ms_h, self.ms_w)
        # print(sh_x, sh_y)
        fr_corrected = tfa.image.translate(fr, (tf.squeeze(tf.stack([sh_x, sh_y], axis=1))), 
                                            interpolation="bilinear")
        # print(tf.math.reduce_sum(fr_corrected))
        
        if self.switch == 0:
            return (tf.reshape(tf.transpose(tf.squeeze(fr_corrected)), [-1])[None, :], [sh_x, sh_y])
        elif self.switch == 1:
            return tf.squeeze(fr_corrected)
        else:
            return [sh_x, sh_y]
    
    def normalize_template(self, template, epsilon=0.00000001):
        # remove mean and divide by std
        template_zm = template - tf.reduce_mean(template, axis=[0,1], keepdims=True)
        template_var = tf.reduce_sum(tf.square(template_zm), axis=[0,1], keepdims=True) + epsilon
        return template_zm, template_var
        
    def normalize_image(self, imgs, shape_template, strides=[1,1,1,1], padding='VALID', epsilon=0.00000001):
        # remove mean and standardize so that normalized cross correlation can be computed
        imgs_zm = imgs - tf.reduce_mean(imgs, axis=[1,2], keepdims=True)
        img_stack = tf.stack([imgs[:,:,:,0], tf.square(imgs)[:,:,:,0]], axis=3)
       
        localsum_stack = tf.nn.avg_pool2d(img_stack,[1,self.template.shape[0]-2*self.ms_w, self.template.shape[1]-2*self.ms_h, 1], 
                                               padding=padding, strides=strides)
        localsum_ustack = tf.unstack(localsum_stack, axis=3)
        localsum_sq = localsum_ustack[1][:,:,:,None]
        localsum = localsum_ustack[0][:,:,:,None]
        imgs_var = localsum_sq - tf.square(localsum)/self.shp_prod + epsilon
        # Remove small machine precision errors after subtraction
        imgs_var = tf.where(imgs_var<0, tf.zeros_like(imgs_var), imgs_var)
        return imgs_zm, imgs_var
        
        
    def extract_fractional_peak(self, ncc, ms_h, ms_w):
        """ use gaussian interpolation to extract a fractional shift
        Args:
            tensor_ncc: tensor
                normalized cross-correlation
                ms_h: max integer shift vertical
                ms_w: max integere shift horizontal
        
        """
        # st = timeit.default_timer()
        shifts_int = self.argmax_2d(ncc) 
        # tf.print(timeit.default_timer() - st, "argmax")

        shifts_int_cast = tf.cast(shifts_int,tf.int32)
        sh_x, sh_y = shifts_int_cast[:,0],shifts_int_cast[:,1]
        # tf.print(timeit.default_timer() - st, "shifts")
        
        sh_x_n = tf.cast(-(sh_x - ms_h), tf.float32)
        sh_y_n = tf.cast(-(sh_y - ms_w), tf.float32)
        
        ncc_log = tf.math.log(ncc)
        # print(ncc_log.shape, np.mean(ncc_log), np.min(ncc))

        n_batches = np.arange(1)

        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x-1, axis=0), tf.squeeze(sh_y, axis=0)]))
        log_xm1_y = tf.gather_nd(ncc_log, idx)
        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x+1, axis=0), tf.squeeze(sh_y, axis=0)]))
        log_xp1_y = tf.gather_nd(ncc_log, idx)
        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x, axis=0), tf.squeeze(sh_y-1, axis=0)]))
        log_x_ym1 = tf.gather_nd(ncc_log, idx)
        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x, axis=0), tf.squeeze(sh_y+1, axis=0)]))
        log_x_yp1 =  tf.gather_nd(ncc_log, idx)
        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x, axis=0), tf.squeeze(sh_y, axis=0)]))
        four_log_xy = 4 * tf.gather_nd(ncc_log, idx)

        sh_x_n = sh_x_n - tf.math.truediv((log_xm1_y - log_xp1_y), (2 * log_xm1_y - four_log_xy + 2 * log_xp1_y))
        sh_y_n = sh_y_n - tf.math.truediv((log_x_ym1 - log_x_yp1), (2 * log_x_ym1 - four_log_xy + 2 * log_x_yp1))

        return tf.reshape(sh_x_n, [1, 1]), tf.reshape(sh_y_n, [1, 1])
    
    def argmax_2d(self, tensor):
        # extract peaks from 2D tensor (takes batches as input too)
        
        # flatten the Tensor along the height and width axes
        flat_tensor = tf.reshape(tensor, (1, tensor.shape[-3]*tensor.shape[-2], 1))

        argmax= tf.cast(tf.argmax(flat_tensor, axis=1), tf.int32)
        # print(argmax, flat_tensor.shape, tensor.shape, "amax")
        # convert indexes into 2D coordinates
        argmax_x = tf.cast(argmax, tf.int32) // tf.shape(tensor)[2]
        argmax_y = tf.cast(argmax, tf.int32) % tf.shape(tensor)[2]
        # print(argmax_x)
        # stack and return 2D coordinates
        return tf.cast(tf.stack((argmax_x, argmax_y), axis=1), tf.float32)
        
    def get_config(self):
        base_config = super().get_config().copy()
        return {**base_config, "template": self.template,"strides": self.strides,
                "padding": self.padding, "epsilon": self.epsilon, "switch": self.switch,
                                        "ms_h": self.ms_h,"ms_w": self.ms_w }
#%%    
class Pipeline(object):    
    def __init__(self, model, y_0, x_0, mc_0, tht2, tot, switch):
        """
        Inputs: the model from get_model, and the initial input values as numpy arrays (y_0, x_0, mc_0, tht2)
        To run, after initializing, run self.get_traces()
        @todo: check if nAtA is computed at every iteration!
        """
        self.model, self.mc0, self.y_0, self.x_0, self.tht2 = model, mc_0, y_0, x_0, tht2
        self.tot = tot
        self.num_neurons = tht2.shape[0]
        self.dim_x, self.dim_y = self.mc0.shape[1], self.mc0.shape[2]
        print(self.mc0.shape)
        self.zero_tensor = [[0.0]]
        if switch == 0:
            self.output_types = {"mc_fr": tf.float32,"shifts": tf.float32}
            self.output_shapes = {"mc_fr":(1, self.dim_x, self.dim_y, 1), "shifts":(2,)}
        elif switch == 1:
            a
        else:
        
        self.frame_input_q = Queue()
        self.spike_input_q = Queue()
        self.output_q = Queue()
        
        #loads estimator from the keras model
        self.estimator = self.load_estimator()
        
        #seed the queues
        self.frame_input_q.put(self.mc0)
        self.spike_input_q.put((self.y_0, self.x_0))

        """Starts extracting frames: extract calls the estimator to predict using the outputs from the generator. 
        Generator works by grabbing the LAST calculated trace and the CURRENT frame and yielding them to the model."""
        self.extraction_thread = Thread(target=self.extract, daemon=True)
        self.extraction_thread.start()
        
    def extract(self):
        # Outputs a dictionary with the outputs from the model (y, x, k, th2)
        for i in self.estimator.predict(input_fn=self.get_dataset, yield_single_examples=False):
            self.output_q.put(i)
    
    def load_estimator(self):
        return tf.keras.estimator.model_to_estimator(keras_model = self.model)

    def get_dataset(self):
        dataset = tf.data.Dataset.from_generator(self.generator, 
                                                 output_types=self.output_types, 
                                                 output_shapes=self.output_shapes)
        return dataset
    
    def generator(self):
        #generator waits until data has been enqueued, then yields the data to the dataset
        while True:
            out = self.spike_input_q.get() # the previous run's traces
            (y, x) = out
            fr = self.frame_input_q.get() # current frame
            
            yield {"m":fr, "y":y, "x":x, "k":self.zero_tensor}

    def get_traces(self, bound):
        #to be called separately. Input "bound" represents the number of frames. 
        #Starts at one because of initial values put on queue.
        output = [0]*bound
        shifts = [0]*bound
        times = [0]*bound
        start = timeit.default_timer()
        print("hi")
        for idx in range(1, bound):
            # print("hi")
            self.frame_input_q.put(self.tot[idx:idx+1,:,:, None])
            # print("hi2")
            out = self.output_q.get()

            self.spike_input_q.put((out["nnls"], out["nnls_1"]))
            # print("hi4")
            output[idx-1] = out["nnls_1"]
            #shifts[idx-1] = out["nnls_4"]
            # time.sleep(0.1)
            times[idx-1]= timeit.default_timer()-start
            
        output[-1] = (self.output_q.get()["nnls_1"])
        print(timeit.default_timer()-start)
        self.frame_input_q.put(self.mc0)
        self.spike_input_q.put((self.y_0, self.x_0))
        # return (output, times)
        return output, shifts, times
           
#%%
def get_mc_model(template, settings="fr", ms_h=10, ms_w=10, switch=0):
    """
    takes as input a template (median) of the movie, A_sp object, and b object from caiman.
    outputs the model: {Motion_Correct layer => Compute_Theta2 layer => NNLS * numlayer}
    """
    shp_x, shp_y = template.shape[0], template.shape[1] #dimensions of the movie
    template = template.astype(np.float32)

    fr_in = tf.keras.layers.Input(shape=tf.TensorShape([shp_x, shp_y]), name="m") #Input layer for one frame of the movie 

    #Initialization of the motion correction layer, initialized with the template
    #import pdb; pdb.set_trace();
    mc_layer = MotionCorrect(template, ms_h=ms_h, ms_w=ms_w, switch=switch)   
    mc, shifts = mc_layer(fr_in)

    #create final model, returns it and the first weight
    model = keras.Model(inputs=[fr_in], outputs=[mc, shifts])   
    return model
#%%
from viola.nnls_gpu import NNLS, compute_theta2

def get_model(template, center_dims, Ab, num_layers=5, ms_h=10, ms_w=10):
    """
    takes as input a template (median) of the movie, A_sp object, and b object from caiman.
    outputs the model: {Motion_Correct layer => Compute_Theta2 layer => NNLS * numlayer}
    """
    shp_x, shp_y = template.shape[0], template.shape[1] #dimensions of the movie
    Ab = Ab.astype(np.float32)
    template = template.astype(np.float32)
    num_components = Ab.shape[-1]

    y_in = tf.keras.layers.Input(shape=tf.TensorShape([num_components, 1]), name="y") # Input Layer for components
    x_in = tf.keras.layers.Input(shape=tf.TensorShape([num_components, 1]), name="x") # Input layer for components
    fr_in = tf.keras.layers.Input(shape=tf.TensorShape([shp_x, shp_y, 1]), name="m") #Input layer for one frame of the movie 
    k_in = tf.keras.layers.Input(shape=(1,), name="k") #Input layer for the counter within the NNLS layers
 
    #Calculations to initialize Motion Correction
    AtA = Ab.T@Ab
    n_AtA = np.linalg.norm(AtA, ord='fro') #Frob. normalization
    theta_1 = (np.eye(Ab.shape[-1]) - AtA/n_AtA)
#    theta_2 = (Atb/n_AtA)[:, None].astype(np.float32)

    #Initialization of the motion correction layer, initialized with the template
    #import pdb; pdb.set_trace();
    mc = tf.reshape(tf.transpose(tf.squeeze(fr_in), [-1]))
    shifts = [0.0, 0.0]
    #Chains motion correction layer to weight-calculation layer
    c_th2 = compute_theta2(Ab, n_AtA)
    (th2, shifts) = c_th2(mc, shifts)
    #Connects weights, calculated from the motion correction, to the NNLS layer
    nnls = NNLS(theta_1)
    x_kk = nnls([y_in, x_in, k_in, th2, shifts])
    #stacks NNLS 9 times
    for j in range(1, num_layers):
        x_kk = nnls(x_kk)
   
    #create final model, returns it and the first weight
    model = keras.Model(inputs=[fr_in, y_in, x_in, k_in], outputs=[x_kk])   
    return model 
#%%
import tensorflow.keras as keras
from threading import Thread
import numpy as np
from FFT_MOTION import MotionCorrect
from viola.nnls_gpu import NNLS, compute_theta2
from queue import Queue 
#%% 
class Pipeline(object):    
    def __init__(self, model, mc0, tot):
        """
        Inputs: the model from get_model, and the initial input values as numpy arrays (y_0, x_0, mc_0, tht2)
        To run, after initializing, run self.get_traces()
        @todo: check if nAtA is computed at every iteration!
        """
        self.model, self.mc0 = model, mc0
        self.tot = tot
        self.dim_x, self.dim_y = self.tot.shape[1], self.tot.shape[2]
        # print(self.mc0.shape)
        # self.zero_tensor = [[0.0]]
        
        self.frame_input_q = Queue()
        self.spike_input_q = Queue()
        self.output_q = Queue()
        
        #loads estimator from the keras model
        self.estimator = self.load_estimator()
        
        #seed the queues
        self.frame_input_q.put(self.mc0)
        # self.spike_input_q.put((self.y_0, self.x_0))

        """Starts extracting frames: extract calls the estimator to predict using the outputs from the generator. 
        Generator works by grabbing the LAST calculated trace and the CURRENT frame and yielding them to the model."""
        self.extraction_thread = Thread(target=self.extract, daemon=True)
        self.extraction_thread.start()
        
    def extract(self):
        # Outputs a dictionary with the outputs from the model (y, x, k, th2)
        for i in self.estimator.predict(input_fn=self.get_dataset, yield_single_examples=False):
            self.output_q.put(i)
    
    def load_estimator(self):
        return tf.keras.estimator.model_to_estimator(keras_model = self.model)

    def get_dataset(self):
        dataset = tf.data.Dataset.from_generator(self.generator, 
                                                 output_types={"m": tf.float32}, 
                                                 output_shapes={"m":(1, self.dim_x, self.dim_y, 1)})
        return dataset
    
    def generator(self):
        #generator waits until data has been enqueued, then yields the data to the dataset
        while True:
            # out = self.spike_input_q.get() # the previous run's traces
            fr = self.frame_input_q.get() # current frame
            
            yield {"m":fr}

    def get_traces(self, bound):
        #to be called separately. Input "bound" represents the number of frames. 
        #Starts at one because of initial values put on queue.
        output = [0]*bound
        shifts = [0]*bound
        times = [0]*bound
        start = timeit.default_timer()
        print("hi")
        for idx in range(1, bound):
            # print("hi")
            self.frame_input_q.put(self.tot[idx:idx+1,:,:, None])
            # print("hi2")
            out = self.output_q.get()
            # print("hi3")
            # self.spike_input_q.put((out["nnls"], out["nnls_1"]))
            # print("hi4")
            output[idx-1] = out["nnls_1"]
            #shifts[idx-1] = out["nnls_4"]
            # time.sleep(0.1)
            times[idx-1]= timeit.default_timer()-start
            
        output[-1] = (self.output_q.get()["nnls_1"])
        print(timeit.default_timer()-start)
        self.frame_input_q.put(self.mc0)
        # self.spike_input_q.put((self.y_0, self.x_0))
        # return (output, times)
        return output, shifts, times
#%%
def get_nnls_model(template, Ab, num_layers=30, ms_h=10, ms_w=10):
    """
    takes as input a template (median) of the movie, A_sp object, and b object from caiman.
    outputs the model: {Motion_Correct layer => Compute_Theta2 layer => NNLS * numlayer}
    """
    shp_x, shp_y = template.shape[0], template.shape[1] #dimensions of the movie
    Ab = Ab.astype(np.float32)
    template = template.astype(np.float32)
    num_components = Ab.shape[-1]

    y_in = tf.keras.layers.Input(shape=tf.TensorShape([num_components, 1]), name="y") # Input Layer for components
    x_in = tf.keras.layers.Input(shape=tf.TensorShape([num_components, 1]), name="x") # Input layer for components
    fr_in = tf.keras.layers.Input(shape=tf.TensorShape([shp_x * shp_y]), name="m") #Input layer for one frame of the movie 
    k_in = tf.keras.layers.Input(shape=(1,), name="k") #Input layer for the counter within the NNLS layers
 
    #Calculations to initialize Motion Correction
    AtA = Ab.T@Ab
    n_AtA = np.linalg.norm(AtA, ord='fro') #Frob. normalization
    theta_1 = (np.eye(Ab.shape[-1]) - AtA/n_AtA)
#    theta_2 = (Atb/n_AtA)[:, None].astype(np.float32)

    #Initialization of the motion correction layer, initialized with the template
    #import pdb; pdb.set_trace();
    shifts = [0.0, 0.0]
    #Chains motion correction layer to weight-calculation layer
    c_th2 = compute_theta2(Ab, n_AtA)
    (th2, shifts) = c_th2(fr_in, shifts)
    #Connects weights, calculated from the motion correction, to the NNLS layer
    nnls = NNLS(theta_1)
    x_kk = nnls([y_in, x_in, k_in, th2, shifts])
    #stacks NNLS 9 times
    for j in range(1, num_layers):
        x_kk = nnls(x_kk)
   
    #create final model, returns it and the first weight
    model = keras.Model(inputs=[fr_in, y_in, x_in, k_in], outputs=[x_kk])   
    return model    