#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Jul 23 16:13:01 2021

@author: nel
"""
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0";
import tensorflow as tf
#tf.compat.v1.disable_eager_execution()
import tensorflow.keras as keras
from threading import Thread
import tensorflow_addons as tfa
import numpy as np
from queue import Queue
import timeit
from time import time
import tensorflow.keras as keras
from scipy.ndimage.filters import gaussian_filter
from fiola.utilities import apply_shifts_dft, local_correlations_movie, play, bin_median_3d
from tifffile.tifffile import imsave
from skimage.io import imread
import matplotlib.pyplot as plt

#%%
class MotionCorrectBatch(keras.layers.Layer):
    def __init__(self, template, batch_size, ms_h=10, ms_w=10, strides=[1,1,1,1], padding='VALID', epsilon=0.00000001, **kwargs):
        
        super().__init__(**kwargs)
        
        self.ms_h = ms_h
        self.ms_w = ms_w
        self.batch_size = batch_size
        
        self.strides = strides
        self.padding = padding
        self.epsilon =  epsilon
        
        self.template = template
        self.template_zm, self.template_var = self.normalize_template(self.template[:,:,None,None], epsilon=self.epsilon)
        
        self.shp = self.template.shape
        self.shp_prod = tf.cast(tf.reduce_prod(self.shp), tf.float32)

        self.shp_m_x, self.shp_m_y = self.shp[0]//2, self.shp[1]//2
        self.target_freq = tf.signal.fft3d(tf.cast(self.template_zm[:,:,:,0], tf.complex128))

        self.target_freq = tf.repeat(self.target_freq[None,:,:,0], repeats=[self.batch_size], axis=0)
            
       
    # @tf.function
    def call(self, fr):

        # fr = tf.cast(fr[None, :, :, None], tf.float32)
        # fr =  fr[0:1,:,:,None]
        fr = fr[0]
        imgs_zm, imgs_var = self.normalize_image(fr, self.shp, strides=self.strides,
                                            padding=self.padding, epsilon=self.epsilon)
        denominator = tf.sqrt(self.template_var * imgs_var)
        # print(imgs_zm.shape, imgs_var.shape)

        
        fr_freq = tf.signal.fft3d(tf.cast(imgs_zm[:,:,:,0], tf.complex128))
        img_product = fr_freq *  tf.math.conj(self.target_freq)

        cross_correlation = tf.cast(tf.math.abs(tf.signal.ifft3d(img_product)), tf.float32)

        rolled_cc =  tf.roll(cross_correlation,(self.batch_size, self.shp_m_x,self.shp_m_y), axis=(0,1,2))

        self.rolled_cc = rolled_cc
        self.denominator = denominator
        self.temp = rolled_cc[:,self.shp_m_x-self.ms_w:self.shp_m_x+self.ms_w+1, self.shp_m_y-self.ms_h:self.shp_m_y+self.ms_h+1, None]
        ncc = rolled_cc[:,self.shp_m_x-self.ms_w:self.shp_m_x+self.ms_w+1, self.shp_m_y-self.ms_h:self.shp_m_y+self.ms_h+1, None]#/denominator

        ncc = tf.where(tf.math.is_nan(ncc), tf.zeros_like(ncc), ncc)

        
        sh_x, sh_y = self.extract_fractional_peak(ncc, self.ms_h, self.ms_w)
        return sh_x, sh_y
        fr_corrected = tfa.image.translate(fr, (tf.squeeze(tf.stack([sh_x, sh_y], axis=1))), 
                                            interpolation="bilinear")

        return tf.reshape(tf.transpose(tf.squeeze(fr_corrected, axis=3), perm=[0,2,1]), (self.batch_size, self.shp[0]*self.shp[1]))

    
    def normalize_template(self, template, epsilon=0.00000001):
        # remove mean and divide by std
        template_zm = template - tf.reduce_mean(template, axis=[0,1], keepdims=True)
        template_var = tf.reduce_sum(tf.square(template_zm), axis=[0,1], keepdims=True) + epsilon
        return template_zm, template_var
        
    def normalize_image(self, imgs, shape_template, strides=[1,1,1,1], padding='VALID', epsilon=0.00000001):
        # remove mean and standardize so that normalized cross correlation can be computed
        # print(imgs.shape)
        imgs_zm = imgs - tf.reduce_mean(imgs, axis=[1,2], keepdims=True)
        img_stack = tf.stack([imgs[:,:,:,0], tf.square(imgs)[:,:,:,0]], axis=3)
        print(img_stack.shape)
        
        localsum_stack = tf.nn.avg_pool2d(img_stack,[1,self.template.shape[0]-2*self.ms_w, self.template.shape[1]-2*self.ms_h, 1], 
                                               padding=padding, strides=strides)
        
        localsum_ustack = tf.unstack(localsum_stack, axis=3)
        localsum_sq = localsum_ustack[1][:,:,:,None]
        localsum = localsum_ustack[0][:,:,:,None]
        
        imgs_var = localsum_sq - tf.square(localsum)/np.prod(shape_template) + epsilon
        # Remove small machine precision errors after subtraction
        imgs_var = tf.where(imgs_var<0, tf.zeros_like(imgs_var), imgs_var)
        return imgs_zm, imgs_var
        
        
    def extract_fractional_peak(self, ncc, ms_h, ms_w):
        """ use gaussian interpolation to extract a fractional shift
        Args:
            tensor_ncc: tensor
                normalized cross-correlation
                ms_h: max integer shift vertical
                ms_w: max integere shift horizontal
        
        """
        # st = timeit.default_timer()
        shifts_int = self.argmax_2d(ncc) 
        # tf.print(timeit.default_timer() - st, "argmax")

        shifts_int_cast = tf.cast(shifts_int,tf.int32)
        sh_x, sh_y = shifts_int_cast[:,0],shifts_int_cast[:,1]
        # tf.print(timeit.default_timer() - st, "shifts")
        
        sh_x_n = tf.cast(-(sh_x - ms_h), tf.float32)
        sh_y_n = tf.cast(-(sh_y - ms_w), tf.float32)
        
        ncc_log = tf.math.log(ncc)

        n_batches = np.arange(self.batch_size)

        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x-1,axis=1), tf.squeeze(sh_y,axis=1)]))
        log_xm1_y = tf.gather_nd(ncc_log, idx)
        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x+1,axis=1), tf.squeeze(sh_y,axis=1)]))
        log_xp1_y = tf.gather_nd(ncc_log, idx)
        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x, axis=1), tf.squeeze(sh_y-1, axis=1)]))
        log_x_ym1 = tf.gather_nd(ncc_log, idx)
        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x, axis=1), tf.squeeze(sh_y+1, axis=1)]))
        log_x_yp1 =  tf.gather_nd(ncc_log, idx)
        idx = tf.transpose(tf.stack([n_batches, tf.squeeze(sh_x, axis=1), tf.squeeze(sh_y, axis=1)]))
        four_log_xy = 4 * tf.gather_nd(ncc_log, idx)

        sh_x_n = sh_x_n - tf.math.truediv((log_xm1_y - log_xp1_y), (2 * log_xm1_y - four_log_xy + 2 * log_xp1_y))
        sh_y_n = sh_y_n - tf.math.truediv((log_x_ym1 - log_x_yp1), (2 * log_x_ym1 - four_log_xy + 2 * log_x_yp1))

        return tf.reshape(sh_x_n, [self.batch_size, 1]), tf.reshape(sh_y_n, [self.batch_size, 1])
    
    def argmax_2d(self, tensor):
        # extract peaks from 2D tensor (takes batches as input too)
        
        # flatten the Tensor along the height and width axes
        flat_tensor = tf.reshape(tensor, (tf.shape(tensor)[0], -1, tf.shape(tensor)[3]))

        argmax= tf.cast(tf.argmax(flat_tensor, axis=1), tf.int32)
        # convert indexes into 2D coordinates
        argmax_x = tf.cast(argmax, tf.int32) // tf.shape(tensor)[2]
        argmax_y = tf.cast(argmax, tf.int32) % tf.shape(tensor)[2]
        # stack and return 2D coordinates
        return tf.cast(tf.stack((argmax_x, argmax_y), axis=1), tf.float32)
        
    def get_config(self):
        base_config = super().get_config().copy()
        return {**base_config, "template": self.template,"strides": self.strides, "batch_size":self.batch_size,
                "padding": self.padding, "epsilon": self.epsilon, 
                                        "ms_h": self.ms_h,"ms_w": self.ms_w }
    
    #%% Generate toy datasets
    D = 2
    
    if D == 3:
        fname = os.path.join('/home/nel/caiman_data', 'example_movies', 'demoMovie3D.tif')
        Y, truth, trueSpikes, centers, dims, shifts = gen_data(D=3, p=2)
        imsave(fname, Y)
        print(fname)#%%
        dims = (70, 50, 10)
        
        Y = imread(fname)   
        Cn = local_correlations_movie(Y, swap_dim=False)
        d1, d2, d3 = dims
        x, y = (int(1.2 * (d1 + d3)), int(1.2 * (d2 + d3)))
        scale = 6/x
        fig = plt.figure(figsize=(scale*x, scale*y))
        axz = fig.add_axes([1-d1/x, 1-d2/y, d1/x, d2/y])
        plt.imshow(Cn.max(2).T, cmap='gray')
        plt.title('Max.proj. z')
        plt.xlabel('x')
        plt.ylabel('y')
        axy = fig.add_axes([0, 1-d2/y, d3/x, d2/y])
        plt.imshow(Cn.max(0), cmap='gray')
        plt.title('Max.proj. x')
        plt.xlabel('z')
        plt.ylabel('y')
        axx = fig.add_axes([1-d1/x, 0, d1/x, d3/y])
        plt.imshow(Cn.max(1).T, cmap='gray')
        plt.title('Max.proj. y')
        plt.xlabel('x')
        plt.ylabel('z');
        plt.show()
        
        play(Y[...,5], magnification=2)
        
    elif D == 2:
        fname = os.path.join('/home/nel/caiman_data', 'example_movies', 'demoMovie2D.tif')
        Y, truth, trueSpikes, centers, dims, shifts = gen_data(D=2, T=256)
        imsave(fname, Y)
        print(fname)#%%
    
    #%%
    if D == 3:
        ms_h = 4; ms_w = 4; ms_d = 2
    elif D == 2:
        if len(Y.shape) != 4:
            Y = Y[..., None]
        ms_h = 5; ms_w = 5; ms_d = 0
    Y = Y.astype(np.float32)
    template = bin_median_3d(Y, 30)
    
    #%%
    mc_layer = MotionCorrectBatch(template[:,:,0], batch_size=1, ms_h=ms_h, ms_w=ms_w)
    data = Y[None, ..., ]
    print(f'data shape: {data.shape}')
    print(f'template shape: {template.shape}')
    sh_x_all = [] 
    sh_y_all = [] 
    
    for i in range(data.shape[1]):
        sh_x, sh_y = mc_layer(data[:,i:i+1])
        sh_x_all.append(sh_x)
        sh_y_all.append(sh_y)
        
    sh_x_all = np.concatenate(sh_x_all, axis=0)
    sh_y_all = np.concatenate(sh_y_all, axis=0) 
        
    #%%
    mc_layer = MotionCorrectBatch(template[:,:,0], batch_size=16, ms_h=ms_h, ms_w=ms_w)
    data = Y[None, ...]
    batch = 16
    sh_x_all = [] 
    sh_y_all = [] 
    shifts_gpu_mc = np.zeros((Y.shape[0], 3))
    for i in range(data.shape[1]//batch):
        sh_x, sh_y = (mc_layer(data[:,batch*i:batch*(i+1)]))
        sh_x_all.append(sh_x)
        sh_y_all.append(sh_y)
        
    sh_x_all = np.concatenate(sh_x_all, axis=0)
    sh_y_all = np.concatenate(sh_y_all, axis=0)        
        #coords = np.array([ncc[0],ncc[1],ncc[2]]).T
        #shifts_gpu_mc[batch*i:batch*(i+1)] = coords
        #shifts_all.append(mc_layer.shifts)
        #times.append(time.time()-st)
    #%%
    plt.plot(-sh_x_all)
    plt.plot(-sh_y_all)
    plt.plot(shifts)
    plt.legend(['fiola inferred x', 'fiola inferred y', 'gt x', 'gt y'])
    
    print(f'correlation x: {np.corrcoef(-sh_x_all.flatten(), shifts[:,0].flatten())[0,1]}')
    print(f'correlation y: {np.corrcoef(-sh_y_all.flatten(), shifts[:,1].flatten())[0,1]}')


    #%%
    mov = np.zeros((4, 70, 50)).astype(np.float32).astype(np.float32)
    #mov = mov + np.random.rand(mov.shape[0], mov.shape[1], mov.shape[2], mov.shape[3])/1.5
    mov = mov.astype(np.float32)
    
    for i in range(mov.shape[0]):
        spot = 5
        mov[i][spot-2:spot+2,spot-2:spot+2] = 20.0
    template = mov[0].copy()
    mov[1] = np.roll(a=mov[0], shift=(1,3), axis=(0,1))
    #mov[2] = np.roll(a=mov[2], shift=(3,3), axis=(0,1))
    #mov[3] = np.roll(a=mov[3], shift=(-2,-3), axis=(0,1))
    data = mov[None, ..., None]#.astype(np.double)  # batch size, time, x, y, z, channel
    
    print(f'data: {data.shape}')
    print(f'template: {template.shape}')
    
    #%%
    mc_layer = MotionCorrectBatch(template, batch_size=1, ms_h=ms_h, ms_w=ms_w)
    #data = Y[None, ..., ]
    print(f'data shape: {data.shape}')
    print(f'template shape: {template.shape}')
    sh_x_all = [] 
    sh_y_all = [] 
    
    for i in range(data.shape[1]):
        sh_x, sh_y = mc_layer(data[:,i:i+1])
        sh_x_all.append(sh_x)
        sh_y_all.append(sh_y)
        
    sh_x_all = np.concatenate(sh_x_all, axis=0)
    sh_y_all = np.concatenate(sh_y_all, axis=0) 
    